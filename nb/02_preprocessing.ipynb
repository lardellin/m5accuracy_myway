{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of time series features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sktime.datatypes import get_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sktime.datatypes import get_examples\n",
    "\n",
    "df = (\n",
    "    pl.read_parquet(\"../data/reduced_table.parquet\")\n",
    "    .sort([\"id\", \"date\"])\n",
    "    .to_pandas()\n",
    "    # [lambda df: df[\"store_id\"]==\"CA_1\"]\n",
    "    # [lambda df: df[\"cat_id\"]==\"FOODS\"]\n",
    "    .assign(\n",
    "        id=lambda df: df[\"id\"].astype(\"category\"),\n",
    "        item_id=lambda df: df[\"item_id\"].astype(\"category\"),\n",
    "        dept_id=lambda df: df[\"dept_id\"].astype(\"category\"),\n",
    "        cat_id=lambda df: df[\"cat_id\"].astype(\"category\"),\n",
    "        store_id=lambda df: df[\"store_id\"].astype(\"category\"),\n",
    "        state_id=lambda df: df[\"state_id\"].astype(\"category\"),\n",
    "        event=lambda df: df[\"event\"].astype(\"category\"),\n",
    "        \n",
    "    )\n",
    "    .set_index([\"id\", \"date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"sales\"].rolling(date=7).mean().isel(id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(da.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.to_unstacked_dataset(\"date\", level=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = xr.DataArray(\n",
    "    np.arange(6).reshape(2, 3),\n",
    "    coords=[(\"x\", [\"a\", \"b\"]), (\"y\", [0, 1, 2])],\n",
    ")\n",
    "data = xr.Dataset({\"a\": arr, \"b\": arr.isel(y=0)})\n",
    "data\n",
    "stacked = data.to_stacked_array(\"z\", [\"x\"])\n",
    "stacked.indexes[\"z\"]\n",
    "roundtripped = stacked.to_unstacked_dataset(dim=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.to_stacked_array(\"z\", [\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "casting all categories to pandas categories is important to be able to define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import mtype, scitype, check_is_scitype, check_is_mtype\n",
    "\n",
    "print(\n",
    "    \"mtype of the dataset: %s\" %\n",
    "    mtype(df.iloc[:10000], as_scitype=\"Hierarchical\")\n",
    ")\n",
    "print(\n",
    "    \"scitype of the dataset: %s\" % \n",
    "    scitype(df.iloc[:10000], candidate_scitypes=\"Hierarchical\")\n",
    ")\n",
    "# scitype(df[\"cat_id\"])\n",
    "# mtype(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what are endogenous and exogenous ts variables\n",
    "target = [\"sales\"]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "exog_lag_features = [\n",
    "    \"sell_price\", \"snap\"\n",
    "]\n",
    "future_features = [\n",
    "    \"event\"\n",
    "]\n",
    "exog_features = exog_lag_features + future_features\n",
    "X = df[exog_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CountVectorizer().fit_transform(df[\"event\"]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, SplineTransformer\n",
    "\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "\n",
    "from sktime.transformations.compose import TransformerPipeline\n",
    "from sktime.transformations.series.date import DateTimeFeatures\n",
    "from sktime.transformations.series.time_since import TimeSince\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.pipeline import sklearn_to_sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_year_feature = TransformerPipeline([\n",
    "        DateTimeFeatures(ts_freq='D', manual_selection=['day_of_year'], \n",
    "                                              keep_original_columns=False),\n",
    "        sklearn_to_sktime(\n",
    "            RepeatingBasisFunction(n_periods=12, input_range=(1, 365))),\n",
    "    ])\n",
    "\n",
    "day_of_week_feature = TransformerPipeline([\n",
    "        DateTimeFeatures(ts_freq='D', manual_selection=['day_of_week'], \n",
    "                                              keep_original_columns=False),\n",
    "        sklearn_to_sktime(OneHotEncoder(sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "trend_feature = TransformerPipeline([\n",
    "        TimeSince(),\n",
    "        sklearn_to_sktime(SplineTransformer(n_knots=4, degree=3, extrapolation='constant'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_feature.fit_transform(X.iloc[:10000], y.iloc[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import YtoX\n",
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "# define autoregressive feature parameters\n",
    "autoregressive_lags_base = {\n",
    "    # \"lag\": [1],\n",
    "    \"lag\": [1, 7], # previous day and -7 days\n",
    "    \"mean\": [[1, 7], [1, 3]], # long and short averages\n",
    "    \"std\": [[1, 7], [1, 3]]\n",
    "}\n",
    "\n",
    "\n",
    "# define autoregressive feature generator\n",
    "autoregressive_feature = TransformerPipeline([\n",
    "    YtoX(),\n",
    "    WindowSummarizer(lag_feature=autoregressive_lags_base),\n",
    "    # LogTransformer(offset=1),\n",
    "    Imputer()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    # .lazy()\n",
    "    .head(10000)\n",
    "    .select(\n",
    "        # pl.col(\"sales\").shift(1).rolling_apply(lambda s: s.mean(), window_size=3).fill_null(strategy=\"backward\").over(\"id\")\n",
    "        **{\n",
    "            f\"{i}_{w}\": pl.col(\"sales\").shift(i).rolling_apply(lambda s: s.mean(), window_size=w).fill_null(pl.all().median()).over(\"id\")\n",
    "            for i, w in product([1], [3, 7, 14])\n",
    "        }\n",
    "    )# .collect()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregressive_feature.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "future_lags = {\n",
    "    \"lag\": [-2, -1, 0, 1]\n",
    "}\n",
    "indicator_autoregressive_feature_generator = TransformerPipeline([\n",
    "    ColumnSelect(future_features),\n",
    "    WindowSummarizer(lag_feature=future_lags,\n",
    "                     target_cols=future_features),\n",
    "    Imputer()\n",
    "])\n",
    "\n",
    "# define feature union for all the Xs of the TS regression\n",
    "feature_generator = FeatureUnion([\n",
    "    ('calendar', calendar_feature_generator),\n",
    "    ('endog_autoregressive', endog_autoregressive_feature_generator),\n",
    "    ('exog_lagged', exog_lagged_autoregressive_feature_generator),\n",
    "    ('exog_futures', indicator_autoregressive_feature_generator)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. time series regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
